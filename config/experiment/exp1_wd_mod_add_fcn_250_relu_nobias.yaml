# @package _global_
defaults:
  - override /dataset: modular_addition
  - override /model: fcn_250

experiment_name: exp1_wd_mod_add_fcn_250_relu_nobias



model:
  parameters:
    activation: relu
    loss: crossentropy
    layers:
      f1: 
        width: 250
        dropout:
          strategy: dropout
          value: 0
        norm: False
        bias: False
      
      output:
        dropout:
          strategy: dropout
          value: 0
        norm: False
        bias: False

    initialization: default
    set_last_layer_to_zero: False
    alpha: 1.0

  name: fcn
  unique_name: null
  #layer_names : null

optimizer:
  name: adamw
  arguments:
    betas: [0.9, 0.98]
    eps: 1e-08

regularization:
  synergy_weight: 0
  redundancy_weight: 0
  features: layer1_post
  cluster_features: False
  max_clusters: 3

training:
  seed: 0
  steps: 4000
  evaluation_step: 5
  train_batch_size: 32
  test_batch_size: 256
  rescale_weight_norm: False
  learning_rate: 1e-3
  weight_decay: 0.00
  alpha: 1

oinfo:
  features : "layer1_post"
  data: train
  cluster_features: True
  
  normalization: gcmi
  evaluation_step: 5
  verbose_cluster: True
  cluster_size: 10
  max_clusters: 20
  batch_size: 200
  lth_steps: [2990000]
  steps: [0, 100, 1950]

clustering:
  cluster_method: hierarchical
  linkage_method: ward
  metric: euclidean
  normalize: False
  num_clusters: 10

wandb:
  enabled: False

set_cluster_folder: True
save_model: True
train_enabled: False
oinfo_enabled: False
lth_enabled: False
acc_enabled: False
gridsearch_enabled: True
overwrite: False
n_jobs_pool: 10

train_percentage_enabled: True
train_percentage: 0.4
train_percentage_size: 10000

model_name: null
exp_folder : null
model_parameters: null

#"layer1_pre", 
gridsearch:
  max_epochs: 4000
  groupby: [weight_decay]
  max_steps: [1500, 1500]
  parameters:

    lth.metric:
      values: ["best_synergy", "best_synergy_inverse"]

    dataset.parameters.frac:
      values: [0.4]

    oinfo.features:
      values: ["layer1_post"]
      #values: ["layer1_post"]

    model.parameters.initialization:
      values: [default]
      
    model.parameters.alpha:
      values:  [1]

    clustering.linkage_method: 
      values: ["ward"]
      #values: ["ward", "complete", "average"]
      #values: ["ward", "complete", "average", "single"]


    clustering.metric:
      #values: ["euclidean"]
      values: ["euclidean"]
      #values: ["euclidean", "l1", "l2", "cosine", "manhattan"]

    clustering.normalize:
      values: [False]
      #values: [False, True]

    model.parameters.activation:
      values: ["relu"]



    training.seed:
      #values: [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]
      #values: [0, 100, 200, 300, 400]
      #values: [0, 100, 200, 300, 400]
      #values: [0, 100, 200]
      values: [0]
      #, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000
    
    training.weight_decay:
      #values: [1, 0.5, 0.4, 0.3, 0.15]
      #values: [0.05, 0.1, 0.2, 0.3, 1]
      #values: [0.05, 0.1, 0.2, 1, 4]
      #values: [0.1, 1]
      #values: [0.05, 0.06, 0.08, 0.1, 0.2, 0.5, 1, 1.5, 2, 4]
      #values: [0.05, 0.06, 0.07, 0.08, 0.1, 1, 1.2, 1.5]
      #values: [0.07, 0.1, 1, 1.2]
      #values: [0.2, 0.3, 0.4, 0.5, 1, 2, 3]
      #values: [0, 0.1, 3, 10]
      #values: [0.1, 0.3, 0.5, 0.7, 0.9, 1, 2, 3, 4]
      #values: [0.1, 0.7, 1, 4]
      #values: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 4, 10, 20, 100]
      #values: [0.01, 0.1, 2, 4, 10]
      #values: [0.1, 2, 2.5, 3, 4]
      #values: [0.1, 2]
      #values: [0.001]
      #values: [0.001, 0.1, 2, 4, 10, 100]
      #values: [0.1, 2, 3, 4, 10]
      #values: [0.1, 2, 10]
      #values: [0.1, 0.5, 1, 2]
      #values: [0.5, 1, 1.5]
      #values: [0.001, 0.1, 2, 3, 4, 10, 100]
      #values: [0, 0.001, 0.1, 2, 10]
      #values: [0.1, 2, 10, 50]
      values: [0.1, 2]
      
  
    training.learning_rate:
      #values: [0.01, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]
      #values: [0.01, 0.03, 0.05, 0.07, 0.1]
      #values: [0.03, 0.1]
      values: [0.03]

    oinfo.cluster_size:
      values: [10]
      #values: [10, 12, 14, 16, 18, 20, 30, 40]
      #values: [10, 20, 40, 60]
    
plots:
  heatmap_1: 
    y: [weight_decay]
    x: [learning_rate]
    z: ["train_test_difference", "test_acc_step", "train_acc_step", "best_train_acc", "best_test_acc", "best_train_loss", "best_test_loss"]
    x_label: "weight decay"
    y_label: "learning rate"
    title: "N "
    max_heatmap_size: 10

lth:
  step: 0
  layer: f1
  metric: synergy
  

#acc:
#  evaluate_specific_steps: [2500]
#  evaluate_specific_step_enabled: True


    
